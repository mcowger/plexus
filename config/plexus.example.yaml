###############################################################################
# Plexus Configuration Documentation
###############################################################################
#
# This file configures the Plexus 2 gateway, defining how requests are routed
# and transformed between different LLM providers.
#
# 1. PROVIDERS SECTION
# --------------------
# Define your upstream AI providers here.
#
#   type:         The transformer architecture used by the provider. 
#                 Common values: OpenAI, Anthropic, OpenRouter.
#   display_name: A friendly name for logging and metadata.
#   api_base_url: The root endpoint for the provider's API.
#   api_key:      Your authentication token for the provider.
#   models:       A list of raw model identifiers supported by this provider.
#                 OR a map of model names to configuration (e.g. pricing).
#   headers:      (Optional) Custom HTTP headers to include in every request.
#
# 2. MODELS SECTION (ALIASES)
# ---------------------------
# Define friendly "Model Aliases" that your clients will use.
#
#   selector:     (Optional) The strategy to select a target.
#                 Values: 'random' (default), 'cost' (future), 'latency' (future).
#   targets:      A list of provider/model pairs this alias routes to.
#                 If multiple targets are provided, Plexus will perform 
#                 selection based on the defined 'selector'.
#
###############################################################################

providers:
  # Standard OpenAI Configuration
  openai:
    type: OpenAI
    display_name: OpenAI
    api_base_url: https://api.openai.com/v1
    api_key: "your-openai-api-key-here"
    models:
      - gpt-4o
      - gpt-4o-mini
      - o1-preview

  # Standard Anthropic Configuration
  anthropic:
    type: Anthropic
    display_name: Anthropic Claude
    api_base_url: https://api.anthropic.com/v1
    api_key: "your-anthropic-api-key-here"
    models:
      - claude-3-5-sonnet-latest
      - claude-3-5-haiku-latest
      - claude-3-opus-latest

  # Standard Google Gemini Configuration
  gemini:
    type: Gemini
    display_name: Google Gemini
    api_base_url: https://generativelanguage.googleapis.com
    api_key: "your-gemini-api-key-here"
    models:
      - gemini-1.5-pro
      - gemini-1.5-flash
      - gemini-2.0-flash-exp

  # Example with Pricing Configuration
  # Pricing is per 1M tokens.
  openai_cost_tracked:
    type: OpenAI
    display_name: OpenAI (Tracked)
    api_base_url: https://api.openai.com/v1
    api_key: "your-openai-api-key-here"
    models:
      gpt-4o:
        pricing:
          source: simple
          input: 2.50
          output: 10.00
      gpt-4o-mini:
        pricing:
          source: simple
          input: 0.15
          output: 0.60

  # Example with Tiered Pricing Configuration (Defined Strategy)
  # Pricing changes based on input token usage volume.
  tiered_pricing_example:
    type: OpenAI
    display_name: Tiered Pricing Provider
    api_base_url: https://api.example.com/v1
    api_key: "your-api-key"
    models:
      tiered-model-v1:
        pricing:
          source: defined
          range:
            # Tier 1: 0 - 1M tokens
            - lower_bound: 0
              upper_bound: 1000000
              input_per_m: 5.00
              output_per_m: 15.00
            # Tier 2: > 1M tokens
            - lower_bound: 1000001
              upper_bound: .inf
              input_per_m: 4.00
              output_per_m: 12.00

  # Example of a Chat-compatible provider (e.g. Together, DeepSeek, Groq)
  deepseek:
    type: OpenAI
    display_name: DeepSeek
    api_base_url: https://api.deepseek.com
    api_key: "your-deepseek-api-key-here"
    models:
      - deepseek-chat
      - deepseek-reasoner

  # Example with custom headers (Required by some aggregators like OpenRouter/Kilo)
  openrouter:
    type: OpenAI
    display_name: OpenRouter
    api_base_url: https://openrouter.ai/api/v1
    api_key: "your-openrouter-key-here"
    models:
      - google/gemini-pro-1.5
    headers:
      "HTTP-Referer": "https://your-app.com"
      "X-Title": "My Plexus App"

models:
  # Basic alias routing to a single target
  smart-model:
    targets:
      - provider: anthropic
        model: claude-3-5-sonnet-latest

  # Alias routing to a Chat-compatible backend
  fast-model:
    targets:
      - provider: openai
        model: gpt-4o-mini

  # Reasoning model alias
  reasoning-model:
    targets:
      - provider: deepseek
        model: deepseek-reasoner

  # Example of Load Balancing with Explicit Selector
  # Requests to 'balanced-model' will distribute randomly across these two targets
  balanced-model:
    selector: random
    targets:
      - provider: openai
        model: gpt-4o
      - provider: anthropic
        model: claude-3-5-sonnet-latest