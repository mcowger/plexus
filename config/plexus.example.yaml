###############################################################################
# Plexus Configuration Documentation
###############################################################################
#
# This file configures the Plexus 2 gateway, defining how requests are routed
# and transformed between different LLM providers.
#
# 1. PROVIDERS SECTION
# --------------------
# Define your upstream AI providers here.
#
#   type:         The transformer architecture used by the provider. 
#                 Common values: OpenAI, Anthropic, OpenRouter.
#   display_name: A friendly name for logging and metadata.
#   api_base_url: The root endpoint for the provider's API.
#   api_key:      Your authentication token for the provider.
#   models:       A list of raw model identifiers supported by this provider.
#   headers:      (Optional) Custom HTTP headers to include in every request.
#
# 2. MODELS SECTION (ALIASES)
# ---------------------------
# Define friendly "Model Aliases" that your clients will use.
#
#   selector:     (Optional) The strategy to select a target.
#                 Values: 'random' (default), 'cost' (future), 'latency' (future).
#   targets:      A list of provider/model pairs this alias routes to.
#                 If multiple targets are provided, Plexus will perform 
#                 selection based on the defined 'selector'.
#
###############################################################################

providers:
  # Standard OpenAI Configuration
  openai:
    type: OpenAI
    display_name: OpenAI
    api_base_url: https://api.openai.com/v1
    api_key: "your-openai-api-key-here"
    models:
      - gpt-4o
      - gpt-4o-mini
      - o1-preview

  # Standard Anthropic Configuration
  anthropic:
    type: Anthropic
    display_name: Anthropic Claude
    api_base_url: https://api.anthropic.com/v1
    api_key: "your-anthropic-api-key-here"
    models:
      - claude-3-5-sonnet-latest
      - claude-3-5-haiku-latest
      - claude-3-opus-latest

  # Standard Google Gemini Configuration
  gemini:
    type: Gemini
    display_name: Google Gemini
    api_base_url: https://generativelanguage.googleapis.com
    api_key: "your-gemini-api-key-here"
    models:
      - gemini-1.5-pro
      - gemini-1.5-flash
      - gemini-2.0-flash-exp


  # Example of an OpenAI-compatible provider (e.g. Together, DeepSeek, Groq)
  deepseek:
    type: OpenAI
    display_name: DeepSeek
    api_base_url: https://api.deepseek.com
    api_key: "your-deepseek-api-key-here"
    models:
      - deepseek-chat
      - deepseek-reasoner

  # Example with custom headers (Required by some aggregators like OpenRouter/Kilo)
  openrouter:
    type: OpenAI
    display_name: OpenRouter
    api_base_url: https://openrouter.ai/api/v1
    api_key: "your-openrouter-key-here"
    models:
      - google/gemini-pro-1.5
    headers:
      "HTTP-Referer": "https://your-app.com"
      "X-Title": "My Plexus App"

models:
  # Basic alias routing to a single target
  smart-model:
    targets:
      - provider: anthropic
        model: claude-3-5-sonnet-latest

  # Alias routing to an OpenAI-compatible backend
  fast-model:
    targets:
      - provider: openai
        model: gpt-4o-mini

  # Reasoning model alias
  reasoning-model:
    targets:
      - provider: deepseek
        model: deepseek-reasoner

  # Example of Load Balancing with Explicit Selector
  # Requests to 'balanced-model' will distribute randomly across these two targets
  balanced-model:
    selector: random
    targets:
      - provider: openai
        model: gpt-4o
      - provider: anthropic
        model: claude-3-5-sonnet-latest