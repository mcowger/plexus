# Plexus 2 Example Configuration

# --- Server Settings ---
server:
  host: "0.0.0.0" # Bind to all interfaces
  port: 4000      # Listen on port 4000

# --- Management API Settings ---
admin:
  apiKey: "admin-secret-key-change-me" # Bearer token for /v0/* endpoints
  rateLimit:
    windowMs: 60000  # 1 minute window
    maxRequests: 100 # Max requests per window

# --- Real-time Events Settings ---
events:
  heartbeatIntervalMs: 30000 # Keep-alive ping interval for SSE
  maxClients: 10             # Maximum concurrent SSE connections

# --- Logging & Observability ---
logging:
  level: "info" # Log level: silly, debug, info, warn, error
  usage:
    enabled: true                     # Enable token usage logging
    storagePath: "./data/logs/usage"  # Directory for usage logs
    retentionDays: 30                 # Keep usage logs for 30 days
  debug:
    enabled: false                    # Capture full request/response traces (high disk usage)
    captureRequests: true             # Include request bodies in traces
    captureResponses: true            # Include response bodies in traces
    storagePath: "./data/logs/debug"  # Directory for debug traces
    retentionDays: 7                  # Keep traces for 7 days
  errors:
    storagePath: "./data/logs/errors" # Directory for error logs
    retentionDays: 90                 # Keep error records for 90 days

# --- LLM Providers ---
providers:
  - name: "openai"
    enabled: true
    apiTypes: ["chat"] # Supported API formats
    baseUrls:
      chat: "https://api.openai.com/v1/chat/completions"
    auth:
      type: "bearer"           # Auth style: bearer or x-api-key
      apiKey: "{env:OPENAI_API_KEY}" # Environment variable name for the key
    models: ["gpt-4o", "gpt-4o-mini", "o1-preview"]
    discount: 1.0              # Cost multiplier (e.g. 0.85 for 15% discount)
    customHeaders:             # Optional headers sent to provider
      "OpenAI-Organization": "org-123"

  - name: "anthropic"
    enabled: true
    apiTypes: ["messages"]
    baseUrls:
      messages: "https://api.anthropic.com/v1/messages"
    auth:
      type: "x-api-key"
      apiKey: "{env:ANTHROPIC_API_KEY}"
    models: ["claude-3-5-sonnet-20241022", "claude-3-opus-20240229"]
    extraBody: # Optional fields merged into every request
      "anthropic_version": "2023-06-01"

# --- Model Aliases & Routing ---
models:
  - alias: "smart"
    description: "High-quality model with multi-provider redundancy"
    additionalAliases:
      - "intelligent"
      - "capable"
    selector: "random" # Options: random, in_order, cost, latency, performance
    # selector: "in_order"    # Use first available, then second
    # selector: "cost"        # Choose cheapest target
    # selector: "latency"     # Choose fastest target
    # selector: "performance" # Best throughput/latency/cost ratio
    targets:
      - provider: "openai"
        model: "gpt-4o"
        weight: 70 # Relative weight for random selection
      - provider: "anthropic"
        model: "claude-3-5-sonnet-20241022"
        weight: 30

  - alias: "fast"
    description: "Low-latency model optimized for speed"
    selector: "latency"
    apiMatch: true # Only consider targets matching client's API type
    targets:
      - provider: "openai"
        model: "gpt-4o-mini"
      - provider: "anthropic"
        model: "claude-3-haiku-20240307"

# --- Client API Keys ---
apiKeys:
  - name: "development-key"
    secret: "plexus-dev-key-123"
    enabled: true
  - name: "production-key"
    secret: "sk-plexus-prod-abc"
    enabled: true

# --- Resilience & Health ---
resilience:
  cooldown:
    storagePath: "./data/cooldowns.json"
    minDuration: 5     # Minimum cooldown seconds
    maxDuration: 3600  # Maximum cooldown seconds
    defaults:
      rate_limit: 60       # Default for 429 errors
      auth_error: 3600     # Default for 401/403 errors
      timeout: 30          # Default for 408/timeouts
      server_error: 120    # Default for 5xx errors
      connection_error: 60 # Default for network failures
  health:
    degradedThreshold: 0.5  # 50% providers down = degraded
    unhealthyThreshold: 0.9 # 90% providers down = unhealthy

# --- Pricing & Cost ---
pricing:
  models:
    "gpt-4o":
      inputPer1M: 2.50
      outputPer1M: 10.00
      cachedPer1M: 1.25
    "claude-3-5-sonnet-20241022":
      inputPer1M: 3.00
      outputPer1M: 15.00
  discounts:
    "openai": 1.0
    "anthropic": 0.9 # Apply 10% discount globally to this provider
  openrouter:
    enabled: false # Dynamically fetch pricing from OpenRouter API
    cacheRefreshMinutes: 60
