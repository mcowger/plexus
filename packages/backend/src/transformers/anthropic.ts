import { Transformer } from "../types/transformer";
import {
  UnifiedChatRequest,
  UnifiedChatResponse,
  UnifiedMessage,
  UnifiedTool,
  MessageContent,
} from "../types/unified";
import { logger } from "../utils/logger";
import { countTokens, getThinkLevel, formatBase64 } from "./utils";
import { createParser, EventSourceMessage } from "eventsource-parser";
import { encode } from "eventsource-encoder";

/**
 * AnthropicTransformer
 *
 * Handles transformation between Anthropic's Messages API and the internal Unified format.
 * Includes specialized logic for content blocks (thinking, tool_use, etc.) and token imputation.
 */
export class AnthropicTransformer implements Transformer {
  name = "messages";
  defaultEndpoint = "/messages";

  /**
   * parseRequest (Client -> Unified)
   * Maps Anthropic's unique system/messages split and content array format to our flat Unified structure.
   */
  async parseRequest(input: any): Promise<UnifiedChatRequest> {
    const messages: UnifiedMessage[] = [];

    // Anthropic uses a separate 'system' field; we merge it as a 'system' role message.
    if (input.system) {
      if (typeof input.system === "string") {
        messages.push({ role: "system", content: input.system });
      } else if (Array.isArray(input.system)) {
        const systemContent = input.system
          .filter((part: any) => part.type === "text")
          .map((part: any) => ({
            type: "text" as const,
            text: part.text,
            cache_control: part.cache_control,
          }));
        messages.push({ role: "system", content: systemContent });
      }
    }

    if (input.messages) {
      for (const msg of input.messages) {
        if (msg.role === "user" || msg.role === "assistant") {
          if (typeof msg.content === "string") {
            messages.push({ role: msg.role, content: msg.content });
          } else if (Array.isArray(msg.content)) {
            const unifiedMsg: UnifiedMessage = { role: msg.role, content: "" };

            // Handle tool results sent by the user
            const toolResults = msg.content.filter(
              (c: any) => c.type === "tool_result"
            );
            if (toolResults.length > 0 && msg.role === "user") {
              for (const tool of toolResults) {
                messages.push({
                  role: "tool",
                  content:
                    typeof tool.content === "string"
                      ? tool.content
                      : JSON.stringify(tool.content),
                  tool_call_id: tool.tool_use_id,
                  cache_control: tool.cache_control,
                });
              }
              const otherParts = msg.content.filter(
                (c: any) => c.type !== "tool_result"
              );
              if (otherParts.length > 0) {
                messages.push({
                  role: "user",
                  content: this.convertAnthropicContent(otherParts),
                });
              }
              continue;
            }

            // Handle tool calls generated by the assistant
            const toolUses = msg.content.filter(
              (c: any) => c.type === "tool_use"
            );
            if (toolUses.length > 0 && msg.role === "assistant") {
              unifiedMsg.tool_calls = toolUses.map((t: any) => ({
                id: t.id,
                type: "function",
                function: {
                  name: t.name,
                  arguments: JSON.stringify(t.input || {}),
                },
              }));
            }

            // Handle Thinking/Reasoning content (Claude 3.7+ feature)
            const thinkingPart = msg.content.find(
              (c: any) => c.type === "thinking"
            );
            if (thinkingPart && msg.role === "assistant") {
              unifiedMsg.thinking = {
                content: thinkingPart.thinking,
                signature: thinkingPart.signature,
              };
            }

            // Handle standard text/image parts
            const contentParts = msg.content.filter(
              (c: any) =>
                c.type !== "tool_use" &&
                c.type !== "tool_result" &&
                c.type !== "thinking"
            );
            if (contentParts.length > 0) {
              unifiedMsg.content = this.convertAnthropicContent(contentParts);
            } else if (unifiedMsg.tool_calls || unifiedMsg.thinking) {
              unifiedMsg.content = null;
            }

            messages.push(unifiedMsg);
          }
        }
      }
    }

    const result: UnifiedChatRequest = {
      messages,
      model: input.model,
      max_tokens: input.max_tokens,
      temperature: input.temperature,
      stream: input.stream,
      tools: input.tools
        ? this.convertAnthropicToolsToUnified(input.tools)
        : undefined,
      tool_choice: input.tool_choice,
    };

    // Map Thinking/Reasoning Configuration
    if (input.thinking) {
      result.reasoning = {
        effort: getThinkLevel(input.thinking.budget_tokens),
        max_tokens: input.thinking.budget_tokens,
        enabled: input.thinking.type === "enabled",
      };
    }

    // Strict Tool Choice Mapping
    if (input.tool_choice) {
      if (typeof input.tool_choice === "object" && input.tool_choice.type === "tool") {
        result.tool_choice = {
          type: "function",
          function: { name: input.tool_choice.name },
        };
      } else if (typeof input.tool_choice === "object" && input.tool_choice.type) {
        result.tool_choice = input.tool_choice.type;
      }
    }

    return result;
  }

  /**
   * formatResponse (Unified -> Client)
   * Maps Unified response back to Anthropic's block-based content format.
   */
  async formatResponse(response: UnifiedChatResponse): Promise<any> {
    const content: any[] = [];

    // Support Annotations/Citations
    if (response.annotations && response.annotations.length > 0) {
      // Use a stable-ish random ID for the server tool
      const toolId = `srvtoolu_${Math.random().toString(36).substring(2, 11)}`;
      content.push({
        type: "server_tool_use",
        id: toolId,
        name: "web_search",
        input: { query: "" },
      });
      content.push({
        type: "web_search_tool_result",
        tool_use_id: toolId,
        content: response.annotations.map((a) => ({
          type: "web_search_result",
          url: a.url_citation?.url,
          title: a.url_citation?.title,
        })),
      });
    }

    if (response.reasoning_content) {
      content.push({
        type: "thinking",
        thinking: response.reasoning_content,
      });
    }

    if (response.content) {
      content.push({ type: "text", text: response.content });
    }

    if (response.tool_calls) {
      for (const toolCall of response.tool_calls) {
        let input = {};
        try {
          const argumentsStr = toolCall.function.arguments || "{}";
          input =
            typeof argumentsStr === "object"
              ? argumentsStr
              : JSON.parse(argumentsStr);
        } catch (e) {
          // Robust Tool Argument Parsing: Wrap in safe state if JSON fails
          input = { raw_arguments: toolCall.function.arguments };
        }
        content.push({
          type: "tool_use",
          id: toolCall.id,
          name: toolCall.function.name,
          input,
        });
      }
    }

    // Fix Stop Reason Mapping: Dynamically set stop_reason
    let stop_reason = "end_turn";
    if (response.tool_calls && response.tool_calls.length > 0) {
      stop_reason = "tool_use";
    }

    return {
      id: response.id,
      type: "message",
      role: "assistant",
      model: response.model,
      content,
      stop_reason,
      stop_sequence: null,
      usage: {
        // Usage Token Normalization: input_tokens = prompt_tokens - cached_tokens
        input_tokens:
          (response.usage?.input_tokens || 0) -
          (response.usage?.cached_tokens || 0),
        output_tokens: response.usage?.output_tokens || 0,
        thinkingTokens: response.usage?.reasoning_tokens || 0,
        cache_read_input_tokens: response.usage?.cached_tokens || 0,
        cache_creation_input_tokens: response.usage?.cache_creation_tokens || 0,
      },
    };
  }

  /**
   * transformRequest (Unified -> Provider)
   */
  async transformRequest(request: UnifiedChatRequest): Promise<any> {
    let system: string | undefined;
    const messages: any[] = [];

    for (const msg of request.messages) {
      if (msg.role === "system") {
        system =
          typeof msg.content === "string"
            ? msg.content
            : JSON.stringify(msg.content);
      } else if (msg.role === "user" || msg.role === "assistant") {
        const content: any[] = [];

        if (msg.thinking) {
          content.push({
            type: "thinking",
            thinking: msg.thinking.content,
            signature: msg.thinking.signature,
          });
        }

        if (msg.content) {
          if (typeof msg.content === "string") {
            content.push({ type: "text", text: msg.content });
          } else if (Array.isArray(msg.content)) {
            for (const part of msg.content) {
              if (part.type === "text") {
                content.push({ type: "text", text: part.text });
              } else if (part.type === "image_url") {
                content.push({
                  type: "image",
                  source: {
                    type: "base64",
                    media_type: part.media_type || "image/jpeg",
                    data: "",
                  },
                });
              }
            }
          }
        }

        if (msg.role === "assistant" && msg.tool_calls) {
          for (const tc of msg.tool_calls) {
            content.push({
              type: "tool_use",
              id: tc.id,
              name: tc.function.name,
              input: JSON.parse(tc.function.arguments),
            });
          }
        }

        messages.push({ role: msg.role, content });
      } else if (msg.role === "tool") {
        messages.push({
          role: "user",
          content: [
            {
              type: "tool_result",
              tool_use_id: msg.tool_call_id,
              content:
                typeof msg.content === "string"
                  ? msg.content
                  : JSON.stringify(msg.content),
            },
          ],
        });
      }
    }

    // Merge consecutive messages of the same role (User+Tool or Assistant+Assistant)
    const mergedMessages: any[] = [];
    for (const msg of messages) {
      if (mergedMessages.length > 0) {
        const last = mergedMessages[mergedMessages.length - 1];
        if (last.role === msg.role) {
          last.content.push(...msg.content);
          continue;
        }
      }
      mergedMessages.push(msg);
    }

    return {
      model: request.model,
      messages: mergedMessages,
      system,
      max_tokens: request.max_tokens || 4096,
      temperature: request.temperature,
      stream: request.stream,
      tools: request.tools
        ? this.convertUnifiedToolsToAnthropic(request.tools)
        : undefined,
    };
  }

  /**
   * transformResponse (Provider -> Unified)
   */
  async transformResponse(response: any): Promise<UnifiedChatResponse> {
    const contentBlocks = response.content || [];
    let text = "";
    let reasoning = "";
    const toolCalls: any[] = [];

    for (const block of contentBlocks) {
      if (block.type === "text") {
        text += block.text;
      } else if (block.type === "thinking") {
        reasoning += block.thinking;
      } else if (block.type === "tool_use") {
        toolCalls.push({
          id: block.id,
          type: "function",
          function: {
            name: block.name,
            arguments: JSON.stringify(block.input),
          },
        });
      }
    }

    const inputTokens = response.usage?.input_tokens || 0;
    const totalOutputTokens = response.usage?.output_tokens || 0;
    const cacheReadTokens = response.usage?.cache_read_input_tokens || 0;
    const cacheCreationTokens =
      response.usage?.cache_creation_input_tokens || 0;

    let realOutputTokens = totalOutputTokens;
    let imputedThinkingTokens = 0;

    // TOKEN IMPUTATION LOGIC:
    // If the provider doesn't explicitly return thinking tokens but has thinking content,
    // we estimate text tokens and assume the remainder is reasoning.
    if (reasoning.length > 0) {
      realOutputTokens = countTokens(text);
      imputedThinkingTokens = Math.max(0, totalOutputTokens - realOutputTokens);
    }

    return {
      id: response.id,
      model: response.model,
      content: text || null,
      reasoning_content: reasoning || null,
      tool_calls: toolCalls.length > 0 ? toolCalls : undefined,
      usage: {
        input_tokens: inputTokens,
        output_tokens: realOutputTokens,
        total_tokens: inputTokens + totalOutputTokens,
        reasoning_tokens: imputedThinkingTokens,
        cached_tokens: cacheReadTokens,
        cache_creation_tokens: cacheCreationTokens,
      },
    };
  }

  /**
   * transformStream (Provider Stream -> Unified Stream)
   * Handles Anthropic's stateful stream events (message_start, content_block_delta, etc.).
   */
  transformStream(stream: ReadableStream): ReadableStream {
    const decoder = new TextDecoder();
    let accumulatedText = "";
    let seenThinking = false;
    let parser: any;
    let messageId: string | undefined;
    let model: string | undefined;

    const transformer = new TransformStream({
      start(controller) {
        parser = createParser({
          onEvent: (event: EventSourceMessage) => {
            if (event.data === "[DONE]") return;

            try {
              const data = JSON.parse(event.data);
              let unifiedChunk: any = null;

              switch (data.type) {
                case "message_start":
                  messageId = data.message.id;
                  model = data.message.model;
                  unifiedChunk = {
                    id: messageId,
                    model: model,
                    created: Math.floor(Date.now() / 1000),
                    delta: { role: "assistant" },
                    usage: data.message.usage
                      ? {
                          input_tokens: data.message.usage.input_tokens || 0,
                          output_tokens: data.message.usage.output_tokens || 0,
                          total_tokens: (data.message.usage.input_tokens || 0) + (data.message.usage.output_tokens || 0),
                          reasoning_tokens: 0,
                          cached_tokens: data.message.usage.cache_read_input_tokens || 0,
                          cache_creation_tokens: data.message.usage.cache_creation_input_tokens || 0,
                        }
                      : undefined,
                  };
                  break;
                case "content_block_delta":
                  if (data.delta.type === "text_delta") {
                    accumulatedText += data.delta.text;
                    unifiedChunk = {
                      delta: { content: data.delta.text },
                    };
                  } else if (data.delta.type === "thinking_delta") {
                    seenThinking = true;
                    unifiedChunk = {
                      delta: { 
                        reasoning_content: data.delta.thinking,
                        thinking: { content: data.delta.thinking }
                      },
                    };
                  } else if (data.delta.type === "signature_delta") {
                    unifiedChunk = {
                      delta: { 
                        thinking: { signature: data.delta.signature }
                      },
                    };
                  } else if (data.delta.type === "input_json_delta") {
                    unifiedChunk = {
                      delta: {
                        tool_calls: [
                          {
                            index: data.index,
                            function: { arguments: data.delta.partial_json },
                          },
                        ],
                      },
                    };
                  }
                  break;
                case "content_block_start":
                  if (data.content_block.type === "tool_use") {
                    unifiedChunk = {
                      delta: {
                        tool_calls: [
                          {
                            index: data.index,
                            id: data.content_block.id,
                            type: "function",
                            function: {
                              name: data.content_block.name,
                              arguments: "",
                            },
                          },
                        ],
                      },
                    };
                  } else if (data.content_block.type === "thinking") {
                    seenThinking = true;
                    unifiedChunk = {
                      delta: {
                        thinking: { content: data.content_block.thinking || "" }
                      }
                    };
                  }
                  break;
                case "message_delta":
                  // Handle usage update and finish reason
                  const inputTokens = data.usage?.input_tokens || 0;
                  const totalOutputTokens = data.usage?.output_tokens || 0;

                  let realOutputTokens = totalOutputTokens;
                  let imputedThinkingTokens = 0;

                  if (seenThinking) {
                    realOutputTokens = countTokens(accumulatedText);
                    imputedThinkingTokens = Math.max(
                      0,
                      totalOutputTokens - realOutputTokens
                    );
                  }

                  unifiedChunk = {
                    finish_reason:
                      data.delta.stop_reason === "end_turn"
                        ? "stop"
                        : data.delta.stop_reason === "tool_use"
                        ? "tool_calls"
                        : data.delta.stop_reason,
                    usage: data.usage
                      ? {
                          input_tokens: inputTokens,
                          output_tokens: realOutputTokens,
                          total_tokens: inputTokens + totalOutputTokens,
                          reasoning_tokens: imputedThinkingTokens,
                          cached_tokens: data.usage.cache_read_input_tokens || 0,
                          cache_creation_tokens: data.usage.cache_creation_input_tokens || 0,
                        }
                      : undefined,
                  };
                  break;
              }

              if (unifiedChunk) {
                controller.enqueue(unifiedChunk);
              }
            } catch (e) {
              logger.error("Error parsing Anthropic stream chunk", e);
            }
          },
        });
      },
      transform(chunk, controller) {
        const text =
          typeof chunk === "string"
            ? chunk
            : decoder.decode(chunk, { stream: true });
        parser.feed(text);
      },
    });

    return stream.pipeThrough(transformer);
  }

  /**
   * formatStream (Unified Stream -> Client Stream)
   * Re-encodes unified chunks into Anthropic's stateful SSE format.
   */
  formatStream(stream: ReadableStream): ReadableStream {
    const encoder = new TextEncoder();
    let hasSentStart = false;
    let hasSentFinish = false;

    // State machine
    let nextBlockIndex = 0;
    let activeBlockType: "text" | "thinking" | "tool_use" | null = null;
    let activeBlockIndex: number | null = null;
    
    // Track usage and finish reason across chunks
    let lastUsage: any = null;
    let pendingFinishReason: string | null = null;

    const transformer = new TransformStream({
      transform(chunk: any, controller) {
        const safeEnqueue = (str: string) => {
          controller.enqueue(encoder.encode(str));
        };

        const sendEvent = (event: string, data: any) => {
          safeEnqueue(encode({ event, data: JSON.stringify(data) }));
        };
        
        // Accumulate Usage
        if (chunk.usage) {
           lastUsage = chunk.usage;
        }

        // 1. Message Start
        if (!hasSentStart) {
          const messageStart = {
            type: "message_start",
            message: {
              id: chunk.id || "msg_" + Date.now(),
              type: "message",
              role: "assistant",
              model: chunk.model,
              content: [],
              stop_reason: null,
              stop_sequence: null,
              usage: {
                input_tokens: chunk.usage?.input_tokens || 0,
                output_tokens: chunk.usage?.output_tokens || 0,
                cache_read_input_tokens: chunk.usage?.cached_tokens || 0,
                cache_creation_input_tokens: chunk.usage?.cache_creation_tokens || 0,
              },
            },
          };
          sendEvent("message_start", messageStart);
          hasSentStart = true;
        }

        const closeCurrentBlock = () => {
          if (activeBlockType !== null && activeBlockIndex !== null) {
            sendEvent("content_block_stop", {
              type: "content_block_stop",
              index: activeBlockIndex,
            });
            activeBlockType = null;
            activeBlockIndex = null;
          }
        };

        const startBlock = (
          type: "text" | "thinking" | "tool_use",
          info?: any
        ) => {
          closeCurrentBlock();

          activeBlockIndex = nextBlockIndex++;
          activeBlockType = type;

          let content_block: any;
          if (type === "text") {
            content_block = { type: "text", text: "" };
          } else if (type === "thinking") {
            content_block = { type: "thinking", thinking: "" };
          } else if (type === "tool_use") {
            content_block = {
              type: "tool_use",
              id: info.id,
              name: info.name,
              input: {},
            };
          }

          sendEvent("content_block_start", {
            type: "content_block_start",
            index: activeBlockIndex,
            content_block,
          });
        };

        if (chunk.delta) {
          // Thinking
          if (chunk.delta.thinking?.content || chunk.delta.reasoning_content) {
            if (activeBlockType !== "thinking") {
              startBlock("thinking");
            }
            sendEvent("content_block_delta", {
              type: "content_block_delta",
              index: activeBlockIndex,
              delta: {
                type: "thinking_delta",
                thinking: chunk.delta.thinking?.content || chunk.delta.reasoning_content,
              },
            });
          }

          if (chunk.delta.thinking?.signature) {
            if (activeBlockType !== "thinking") {
              startBlock("thinking");
            }
            sendEvent("content_block_delta", {
              type: "content_block_delta",
              index: activeBlockIndex,
              delta: {
                type: "signature_delta",
                signature: chunk.delta.thinking.signature,
              },
            });
          }

          // Text
          if (chunk.delta.content) {
            if (activeBlockType !== "text") {
              startBlock("text");
            }
            sendEvent("content_block_delta", {
              type: "content_block_delta",
              index: activeBlockIndex,
              delta: { type: "text_delta", text: chunk.delta.content },
            });
          }

          // Tool Calls
          if (chunk.delta.tool_calls) {
            for (const tc of chunk.delta.tool_calls) {
              if (tc.id) {
                startBlock("tool_use", { id: tc.id, name: tc.function?.name });
              }

              if (tc.function?.arguments) {
                if (
                  activeBlockType === "tool_use" &&
                  activeBlockIndex !== null
                ) {
                  sendEvent("content_block_delta", {
                    type: "content_block_delta",
                    index: activeBlockIndex,
                    delta: {
                      type: "input_json_delta",
                      partial_json: tc.function.arguments,
                    },
                  });
                }
              }
            }
          }
        }

        // Capture Finish Reason
        if (chunk.finish_reason) {
          closeCurrentBlock();
          
          // Store finish reason but defer sending completion events
          // to allow subsequent chunks (like usage) to be processed.
          const mapping: Record<string, string> = {
            stop: "end_turn",
            length: "max_tokens",
            tool_calls: "tool_use",
            content_filter: "stop_sequence",
          };

          pendingFinishReason = mapping[chunk.finish_reason] || chunk.finish_reason;
        }
      },
      flush(controller) {
        // Robust Termination: ensure message_delta and message_stop are sent
        if (hasSentStart && !hasSentFinish) {
          const safeEnqueue = (str: string) => {
            controller.enqueue(encoder.encode(str));
          };
          const sendEvent = (event: string, data: any) => {
            safeEnqueue(encode({ event, data: JSON.stringify(data) }));
          };

          if (activeBlockType !== null && activeBlockIndex !== null) {
            sendEvent("content_block_stop", {
              type: "content_block_stop",
              index: activeBlockIndex,
            });
          }

          // Send message_delta with collected usage and stop reason
          sendEvent("message_delta", {
            type: "message_delta",
            delta: {
              stop_reason: pendingFinishReason || "end_turn",
              stop_sequence: null,
            },
            usage: lastUsage ? {
              input_tokens: lastUsage.input_tokens,
              output_tokens: lastUsage.output_tokens,
              cache_read_input_tokens: lastUsage.cached_tokens,
            } : undefined
          });
          
          sendEvent("message_stop", { type: "message_stop" });
          hasSentFinish = true;
        }
      }
    });

    return stream.pipeThrough(transformer);
  }

  // Helpers

  private convertAnthropicContent(content: any[]): string | MessageContent[] {
    const parts: MessageContent[] = [];
    for (const c of content) {
      if (c.type === "text") {
        parts.push({
          type: "text",
          text: c.text,
          cache_control: c.cache_control,
        });
      } else if (c.type === "image" && c.source) {
        parts.push({
          type: "image_url",
          image_url: {
            url:
              c.source.type === "base64"
                ? formatBase64(c.source.data, c.source.media_type)
                : c.source.url,
          },
          media_type: c.source.media_type,
        });
      }
    }
    if (!parts.length) return "";
    const firstPart = parts[0];
    if (parts.length === 1 && firstPart?.type === "text") return firstPart.text;
    return parts;
  }

  private convertAnthropicToolsToUnified(tools: any[]): UnifiedTool[] {
    return tools.map((t) => ({
      type: "function",
      function: {
        name: t.name,
        description: t.description,
        parameters: t.input_schema,
      },
    }));
  }

  private convertUnifiedToolsToAnthropic(tools: UnifiedTool[]): any[] {
    return tools.map((t) => ({
      name: t.function.name,
      description: t.function.description,
      input_schema: t.function.parameters,
    }));
  }

  /**
   * Extract usage from Anthropic-style event data (already parsed JSON string)
   */
  extractUsage(dataStr: string):
    | {
        input_tokens?: number;
        output_tokens?: number;
        cached_tokens?: number;
        reasoning_tokens?: number;
      }
    | undefined {
    try {
      const data = JSON.parse(dataStr);

      // Anthropic sends usage in message_start and message_delta events
      if (data.type === "message_start" && data.message?.usage) {
        return {
          input_tokens: data.message.usage.input_tokens || 0,
          output_tokens: data.message.usage.output_tokens || 0,
          cached_tokens:
            data.message.usage.cache_read_input_tokens ||
            data.message.usage.cache_creation_input_tokens ||
            0,
          reasoning_tokens: 0,
        };
      }

      if (data.type === "message_delta" && data.usage) {
        return {
          input_tokens: data.usage.input_tokens || 0,
          output_tokens: data.usage.output_tokens || 0,
          cached_tokens: data.usage.cache_read_input_tokens || 0,
          reasoning_tokens: 0,
        };
      }
    } catch (e) {
      // Ignore parse errors
    }

    return undefined;
  }
}