import { Transformer } from "../types/transformer";
import {
  UnifiedChatRequest,
  UnifiedChatResponse,
  UnifiedMessage,
  UnifiedTool,
  MessageContent,
} from "../types/unified";
import { logger } from "../utils/logger";
import { countTokens } from "./utils";
import { createParser, EventSourceMessage } from "eventsource-parser";
import { encode } from "eventsource-encoder";

/**
 * AnthropicTransformer
 *
 * Handles transformation between Anthropic's Messages API and the internal Unified format.
 * Includes specialized logic for content blocks (thinking, tool_use, etc.) and token imputation.
 */
export class AnthropicTransformer implements Transformer {
  name = "messages";
  defaultEndpoint = "/messages";

  /**
   * parseRequest (Client -> Unified)
   * Maps Anthropic's unique system/messages split and content array format to our flat Unified structure.
   */
  async parseRequest(input: any): Promise<UnifiedChatRequest> {
    const messages: UnifiedMessage[] = [];

    // Anthropic uses a separate 'system' field; we merge it as a 'system' role message.
    if (input.system) {
      messages.push({ role: "system", content: input.system });
    }

    if (input.messages) {
      for (const msg of input.messages) {
        if (msg.role === "user" || msg.role === "assistant") {
          if (typeof msg.content === "string") {
            messages.push({ role: msg.role, content: msg.content });
          } else if (Array.isArray(msg.content)) {
            const unifiedMsg: UnifiedMessage = { role: msg.role, content: "" };

            // Handle tool results sent by the user
            const toolResults = msg.content.filter(
              (c: any) => c.type === "tool_result"
            );
            if (toolResults.length > 0 && msg.role === "user") {
              for (const tool of toolResults) {
                messages.push({
                  role: "tool",
                  content:
                    typeof tool.content === "string"
                      ? tool.content
                      : JSON.stringify(tool.content),
                  tool_call_id: tool.tool_use_id,
                });
              }
              const otherParts = msg.content.filter(
                (c: any) => c.type !== "tool_result"
              );
              if (otherParts.length > 0) {
                messages.push({
                  role: "user",
                  content: this.convertAnthropicContent(otherParts),
                });
              }
              continue;
            }

            // Handle tool calls generated by the assistant
            const toolUses = msg.content.filter(
              (c: any) => c.type === "tool_use"
            );
            if (toolUses.length > 0 && msg.role === "assistant") {
              unifiedMsg.tool_calls = toolUses.map((t: any) => ({
                id: t.id,
                type: "function",
                function: {
                  name: t.name,
                  arguments: JSON.stringify(t.input),
                },
              }));
            }

            // Handle Thinking/Reasoning content (Claude 3.7+ feature)
            const thinkingPart = msg.content.find(
              (c: any) => c.type === "thinking"
            );
            if (thinkingPart && msg.role === "assistant") {
              unifiedMsg.thinking = {
                content: thinkingPart.thinking,
                signature: thinkingPart.signature,
              };
            }

            // Handle standard text/image parts
            const contentParts = msg.content.filter(
              (c: any) =>
                c.type !== "tool_use" &&
                c.type !== "tool_result" &&
                c.type !== "thinking"
            );
            if (contentParts.length > 0) {
              unifiedMsg.content = this.convertAnthropicContent(contentParts);
            } else if (unifiedMsg.tool_calls || unifiedMsg.thinking) {
              unifiedMsg.content = null;
            }

            messages.push(unifiedMsg);
          }
        }
      }
    }

    return {
      messages,
      model: input.model,
      max_tokens: input.max_tokens,
      temperature: input.temperature,
      stream: input.stream,
      tools: input.tools
        ? this.convertAnthropicToolsToUnified(input.tools)
        : undefined,
      tool_choice: input.tool_choice,
    };
  }

  /**
   * formatResponse (Unified -> Client)
   * Maps Unified response back to Anthropic's block-based content format.
   */
  async formatResponse(response: UnifiedChatResponse): Promise<any> {
    const content: any[] = [];

    if (response.reasoning_content) {
      content.push({
        type: "thinking",
        thinking: response.reasoning_content,
      });
    }

    if (response.content) {
      content.push({ type: "text", text: response.content });
    }

    if (response.tool_calls) {
      for (const toolCall of response.tool_calls) {
        content.push({
          type: "tool_use",
          id: toolCall.id,
          name: toolCall.function.name,
          input: JSON.parse(toolCall.function.arguments),
        });
      }
    }

    return {
      id: response.id,
      type: "message",
      role: "assistant",
      model: response.model,
      content,
      stop_reason: "end_turn",
      stop_sequence: null,
      usage: {
        input_tokens: response.usage?.input_tokens || 0,
        output_tokens: response.usage?.output_tokens || 0,
        thinkingTokens: response.usage?.reasoning_tokens || 0,
        cache_read_input_tokens: response.usage?.cached_tokens || 0,
        cache_creation_input_tokens: response.usage?.cache_creation_tokens || 0,
      },
    };
  }

  /**
   * transformRequest (Unified -> Provider)
   */
  async transformRequest(request: UnifiedChatRequest): Promise<any> {
    let system: string | undefined;
    const messages: any[] = [];

    for (const msg of request.messages) {
      if (msg.role === "system") {
        system =
          typeof msg.content === "string"
            ? msg.content
            : JSON.stringify(msg.content);
      } else if (msg.role === "user" || msg.role === "assistant") {
        const content: any[] = [];

        if (msg.thinking) {
          content.push({
            type: "thinking",
            thinking: msg.thinking.content,
            signature: msg.thinking.signature,
          });
        }

        if (msg.content) {
          if (typeof msg.content === "string") {
            content.push({ type: "text", text: msg.content });
          } else if (Array.isArray(msg.content)) {
            for (const part of msg.content) {
              if (part.type === "text") {
                content.push({ type: "text", text: part.text });
              } else if (part.type === "image_url") {
                content.push({
                  type: "image",
                  source: {
                    type: "base64",
                    media_type: part.media_type || "image/jpeg",
                    data: "",
                  },
                });
              }
            }
          }
        }

        if (msg.role === "assistant" && msg.tool_calls) {
          for (const tc of msg.tool_calls) {
            content.push({
              type: "tool_use",
              id: tc.id,
              name: tc.function.name,
              input: JSON.parse(tc.function.arguments),
            });
          }
        }

        messages.push({ role: msg.role, content });
      } else if (msg.role === "tool") {
        messages.push({
          role: "user",
          content: [
            {
              type: "tool_result",
              tool_use_id: msg.tool_call_id,
              content:
                typeof msg.content === "string"
                  ? msg.content
                  : JSON.stringify(msg.content),
            },
          ],
        });
      }
    }

    // Merge consecutive user/assistant messages (Fastify cleanup)
    const mergedMessages: any[] = [];
    for (const msg of messages) {
      if (mergedMessages.length > 0) {
        const last = mergedMessages[mergedMessages.length - 1];
        if (last.role === msg.role && msg.role === "user") {
          last.content.push(...msg.content);
          continue;
        }
      }
      mergedMessages.push(msg);
    }

    return {
      model: request.model,
      messages: mergedMessages,
      system,
      max_tokens: request.max_tokens || 4096,
      temperature: request.temperature,
      stream: request.stream,
      tools: request.tools
        ? this.convertUnifiedToolsToAnthropic(request.tools)
        : undefined,
    };
  }

  /**
   * transformResponse (Provider -> Unified)
   */
  async transformResponse(response: any): Promise<UnifiedChatResponse> {
    const contentBlocks = response.content || [];
    let text = "";
    let reasoning = "";
    const toolCalls: any[] = [];

    for (const block of contentBlocks) {
      if (block.type === "text") {
        text += block.text;
      } else if (block.type === "thinking") {
        reasoning += block.thinking;
      } else if (block.type === "tool_use") {
        toolCalls.push({
          id: block.id,
          type: "function",
          function: {
            name: block.name,
            arguments: JSON.stringify(block.input),
          },
        });
      }
    }

    const inputTokens = response.usage?.input_tokens || 0;
    const totalOutputTokens = response.usage?.output_tokens || 0;
    const cacheReadTokens = response.usage?.cache_read_input_tokens || 0;
    const cacheCreationTokens =
      response.usage?.cache_creation_input_tokens || 0;

    let realOutputTokens = totalOutputTokens;
    let imputedThinkingTokens = 0;

    // TOKEN IMPUTATION LOGIC:
    // If the provider doesn't explicitly return thinking tokens but has thinking content,
    // we estimate text tokens and assume the remainder is reasoning.
    if (reasoning.length > 0) {
      realOutputTokens = countTokens(text);
      imputedThinkingTokens = Math.max(0, totalOutputTokens - realOutputTokens);
    }

    return {
      id: response.id,
      model: response.model,
      content: text || null,
      reasoning_content: reasoning || null,
      tool_calls: toolCalls.length > 0 ? toolCalls : undefined,
      usage: {
        input_tokens: inputTokens,
        output_tokens: realOutputTokens,
        total_tokens: inputTokens + totalOutputTokens,
        reasoning_tokens: imputedThinkingTokens,
        cached_tokens: cacheReadTokens,
        cache_creation_tokens: cacheCreationTokens,
      },
    };
  }

  /**
   * transformStream (Provider Stream -> Unified Stream)
   * Handles Anthropic's stateful stream events (message_start, content_block_delta, etc.).
   */
  transformStream(stream: ReadableStream): ReadableStream {
    const decoder = new TextDecoder();
    let accumulatedText = "";
    let seenThinking = false;
    let parser: any;

    const transformer = new TransformStream({
      start(controller) {
        parser = createParser({
          onEvent: (event: EventSourceMessage) => {
            if (event.data === "[DONE]") return;

            try {
              const data = JSON.parse(event.data);
              let unifiedChunk: any = null;

              switch (data.type) {
                case "message_start":
                  unifiedChunk = {
                    id: data.message.id,
                    model: data.message.model,
                    created: Math.floor(Date.now() / 1000),
                    delta: { role: "assistant" },
                  };
                  break;
                case "content_block_delta":
                  if (data.delta.type === "text_delta") {
                    accumulatedText += data.delta.text;
                    unifiedChunk = {
                      delta: { content: data.delta.text },
                    };
                  } else if (data.delta.type === "thinking_delta") {
                    seenThinking = true;
                    unifiedChunk = {
                      delta: { reasoning_content: data.delta.thinking },
                    };
                  } else if (data.delta.type === "input_json_delta") {
                    unifiedChunk = {
                      delta: {
                        tool_calls: [
                          {
                            index: data.index,
                            function: { arguments: data.delta.partial_json },
                          },
                        ],
                      },
                    };
                  }
                  break;
                case "content_block_start":
                  if (data.content_block.type === "tool_use") {
                    unifiedChunk = {
                      delta: {
                        tool_calls: [
                          {
                            index: data.index,
                            id: data.content_block.id,
                            type: "function",
                            function: {
                              name: data.content_block.name,
                              arguments: "",
                            },
                          },
                        ],
                      },
                    };
                  }
                  break;
                case "message_delta":
                  // Handle usage update and finish reason
                  const inputTokens = data.usage?.input_tokens || 0;
                  const totalOutputTokens = data.usage?.output_tokens || 0;

                  let realOutputTokens = totalOutputTokens;
                  let imputedThinkingTokens = 0;

                  if (seenThinking) {
                    realOutputTokens = countTokens(accumulatedText);
                    imputedThinkingTokens = Math.max(
                      0,
                      totalOutputTokens - realOutputTokens
                    );
                  }

                  unifiedChunk = {
                    finish_reason:
                      data.delta.stop_reason === "end_turn"
                        ? "stop"
                        : data.delta.stop_reason === "tool_use"
                        ? "tool_calls"
                        : data.delta.stop_reason,
                    usage: data.usage
                      ? {
                          input_tokens: inputTokens,
                          output_tokens: realOutputTokens,
                          total_tokens: inputTokens + totalOutputTokens,
                          reasoning_tokens: imputedThinkingTokens,
                          cached_tokens: 0,
                          cache_creation_tokens: 0,
                        }
                      : undefined,
                  };
                  break;
              }

              if (unifiedChunk) {
                logger.silly(
                  `Anthropic Transformer: Enqueueing unified chunk`,
                  unifiedChunk
                );
                controller.enqueue(unifiedChunk);
              }
            } catch (e) {
              logger.error("Error parsing Anthropic stream chunk", e);
            }
          },
        });
      },
      transform(chunk, controller) {
        const text =
          typeof chunk === "string"
            ? chunk
            : decoder.decode(chunk, { stream: true });
        parser.feed(text);
      },
    });

    return stream.pipeThrough(transformer);
  }

  /**
   * formatStream (Unified Stream -> Client Stream)
   * Re-encodes unified chunks into Anthropic's stateful SSE format.
   */
  formatStream(stream: ReadableStream): ReadableStream {
    const encoder = new TextEncoder();
    let hasSentStart = false;

    const transformer = new TransformStream({
      transform(chunk: any, controller) {
        // Anthropic requires a message_start event first
        if (!hasSentStart) {
          const messageStart = {
            type: "message_start",
            message: {
              id: chunk.id || "msg_" + Date.now(),
              type: "message",
              role: "assistant",
              model: chunk.model,
              content: [],
              stop_reason: null,
              stop_sequence: null,
              usage: { input_tokens: 0, output_tokens: 0 },
            },
          };
          const sseMessage = encode({
            event: "message_start",
            data: JSON.stringify(messageStart),
          });
          controller.enqueue(encoder.encode(sseMessage));
          hasSentStart = true;
        }

        if (chunk.delta) {
          if (chunk.delta.content) {
            const textDelta = {
              type: "content_block_delta",
              index: 0,
              delta: { type: "text_delta", text: chunk.delta.content },
            };
            const sseMessage = encode({
              event: "content_block_delta",
              data: JSON.stringify(textDelta),
            });
            controller.enqueue(encoder.encode(sseMessage));
          }

          if (chunk.delta.reasoning_content) {
            const thinkingDelta = {
              type: "content_block_delta",
              index: 0,
              delta: {
                type: "thinking_delta",
                thinking: chunk.delta.reasoning_content,
              },
            };
            const sseMessage = encode({
              event: "content_block_delta",
              data: JSON.stringify(thinkingDelta),
            });
            controller.enqueue(encoder.encode(sseMessage));
          }

          if (chunk.delta.tool_calls) {
            for (const tc of chunk.delta.tool_calls) {
              const toolDelta = {
                type: "content_block_delta",
                index: tc.index || 0,
                delta: {
                  type: "input_json_delta",
                  partial_json: tc.function?.arguments || "",
                },
              };
              const sseMessage = encode({
                event: "content_block_delta",
                data: JSON.stringify(toolDelta),
              });
              controller.enqueue(encoder.encode(sseMessage));
            }
          }
        }

        if (chunk.finish_reason) {
          const messageDelta = {
            type: "message_delta",
            delta: {
              stop_reason:
                chunk.finish_reason === "stop"
                  ? "end_turn"
                  : chunk.finish_reason === "tool_calls"
                  ? "tool_use"
                  : chunk.finish_reason,
              stop_sequence: null,
            },
            usage: chunk.usage
              ? {
                  output_tokens: chunk.usage.output_tokens,
                  thinkingTokens: chunk.usage.reasoning_tokens,
                }
              : undefined,
          };
          const sseMessage = encode({
            event: "message_delta",
            data: JSON.stringify(messageDelta),
          });
          controller.enqueue(encoder.encode(sseMessage));

          const messageStop = { type: "message_stop" };
          const sseStop = encode({
            event: "message_stop",
            data: JSON.stringify(messageStop),
          });
          controller.enqueue(encoder.encode(sseStop));
        }
      },
    });

    return stream.pipeThrough(transformer);
  }

  // Helpers

  private convertAnthropicContent(content: any[]): string | MessageContent[] {
    const parts: MessageContent[] = [];
    for (const c of content) {
      if (c.type === "text") parts.push({ type: "text", text: c.text });
    }
    if (!parts.length) return "";
    if (!parts[0]) return "";
    if (parts.length === 1 && parts[0].type === "text") return parts[0].text;
    return parts;
  }

  private convertAnthropicToolsToUnified(tools: any[]): UnifiedTool[] {
    return tools.map((t) => ({
      type: "function",
      function: {
        name: t.name,
        description: t.description,
        parameters: t.input_schema,
      },
    }));
  }

  private convertUnifiedToolsToAnthropic(tools: UnifiedTool[]): any[] {
    return tools.map((t) => ({
      name: t.function.name,
      description: t.function.description,
      input_schema: t.function.parameters,
    }));
  }

  /**
   * Extract usage from Anthropic-style event data (already parsed JSON string)
   */
  extractUsage(dataStr: string):
    | {
        input_tokens?: number;
        output_tokens?: number;
        cached_tokens?: number;
        reasoning_tokens?: number;
      }
    | undefined {
    try {
      const data = JSON.parse(dataStr);

      // Anthropic sends usage in message_start and message_delta events
      if (data.type === "message_start" && data.message?.usage) {
        return {
          input_tokens: data.message.usage.input_tokens || 0,
          output_tokens: data.message.usage.output_tokens || 0,
          cached_tokens:
            data.message.usage.cache_read_input_tokens ||
            data.message.usage.cache_creation_input_tokens ||
            0,
          reasoning_tokens: 0,
        };
      }

      if (data.type === "message_delta" && data.usage) {
        return {
          input_tokens: 0,
          output_tokens: data.usage.output_tokens || 0,
          cached_tokens: 0,
          reasoning_tokens: 0,
        };
      }
    } catch (e) {
      // Ignore parse errors
    }

    return undefined;
  }
}
